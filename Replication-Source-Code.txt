// ===============================
// Web API Replication Script
// ===============================
// Replicates multiple OData queries and writes results to JSON.
// Requires Node.js 18+ (uses native fetch).

import { mkdir, writeFile } from "node:fs/promises";

const debug = false;

// Replace with your actual token(s)
const headers = {
  Authorization: `Bearer ${process.env.ACCESS_TOKEN || "your-access-token"}`
};

// Define your inputs here
const inputs = [
  {
    name: "property",
    enabled: true,
    url: `https://query.ampre.ca/odata/Property?$filter=ContractStatus eq 'Available' and (ModificationTimestamp gt @lastTimestampValue or (ModificationTimestamp eq @lastTimestampValue and ListingKey gt '@lastKeyValue'))&$orderby=ModificationTimestamp,ListingKey`,
    headers,
    batchSize: 1000,
    keyField: "ListingKey",
    timestampField: "ModificationTimestamp",
    lastTimestampValue: "1970-01-01T00:00:00Z",
    lastKeyValue: "0",
    writePath: "./data/property"
  },
  {
    name: "media",
    enabled: true,
    url: `https://query.ampre.ca/odata/Media?$filter=ModificationTimestamp gt @lastTimestampValue or (ModificationTimestamp eq @lastTimestampValue and MediaKey gt '@lastKeyValue')&$orderby=ModificationTimestamp,MediaKey`,
    headers,
    batchSize: 500, // Adjust as needed for load
    keyField: "MediaKey",
    timestampField: "ModificationTimestamp",
    lastTimestampValue: new Date(Date.now() - 24 * 60 * 60 * 1000).toISOString(),
    lastKeyValue: "0",
    writePath: "./data/media"
  }
];

// Entry point
run().catch((err) => {
  console.error(err);
  process.exit(1);
});

async function run() {
  const start = new Date();

  for (const input of inputs) {
    if (!input.enabled) continue;
    await runInput(input);
  }

  console.log(`[run] Total runtime: ${(new Date() - start) / 1000}s`);
}

async function runInput(input) {
  const { name, batchSize, keyField, timestampField, writePath } = input;
  let lastTimestampValue = input.lastTimestampValue;
  let lastKeyValue = input.lastKeyValue;

  console.log(`[input] Running: ${name}`);

  const count = await fetchCount(input, lastTimestampValue, lastKeyValue);
  let lastCount = batchSize;
  let totalCount = 0;
  const seenKeys = new Set();

  while (lastCount >= batchSize) {
    const records = await fetchBatch(
      input,
      timestampField,
      lastTimestampValue,
      keyField,
      lastKeyValue
    );

    for (const record of records) {
      const key = record[keyField];
      const timestamp = record[timestampField];
      totalCount++;

      if (seenKeys.has(key)) {
        console.log(`[input] Duplicate key: ${key}`);
      } else {
        seenKeys.add(key);
      }

      if (writePath) await writeRecord(writePath, key, record);

      lastTimestampValue = timestamp;
      lastKeyValue = key;
    }

    lastCount = records.length;
  }

  console.log(
    `[input] Expected: ${count}, Fetched: ${seenKeys.size} unique / ${totalCount} total in ${(new Date() - new Date()) / 1000}s`
  );
}

async function fetchCount({ url, headers }, lastTimestampValue, lastKeyValue) {
  let countUrl = `${url
    .replace(/@lastTimestampValue/g, lastTimestampValue)
    .replace(/@lastKeyValue/g, lastKeyValue)}&$top=0&$count=true`;

  countUrl = encodeURI(countUrl);
  if (debug) console.log(countUrl);

  const res = await fetch(countUrl, { headers });
  if (res.status !== 200) throw new Error(`Count failed: ${res.status}`);

  const json = await res.json();
  console.log(`[count] total: ${json["@odata.count"]}`);
  return json["@odata.count"];
}

async function fetchBatch({ url, headers, batchSize }, timestampField, lastTimestampValue, keyField, lastKeyValue) {
  let batchUrl = `${url
    .replace(/@lastTimestampValue/g, lastTimestampValue)
    .replace(/@lastKeyValue/g, lastKeyValue)}&$top=${batchSize}`;

  batchUrl = encodeURI(batchUrl);
  if (debug) console.log(batchUrl);

  const res = await fetch(batchUrl, { headers });
  if (res.status !== 200) throw new Error(`Batch failed: ${res.status}`);

  const json = await res.json();
  console.log(`[batch] ${timestampField}: ${lastTimestampValue} key: ${lastKeyValue} records: ${json.value.length}`);
  return json.value;
}

async function writeRecord(writePath, key, record) {
  await mkdir(writePath, { recursive: true });
  const filepath = `${writePath}/${key}.json`;
  await writeFile(filepath, JSON.stringify(record));
}
